{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<TensorSliceDataset shapes: (), types: tf.string>\n['aeroplane' 'bicycle' 'bird' 'boat' 'bottle' 'bus' 'car' 'cat' 'chair'\n 'cow' 'diningtable' 'dog' 'horse' 'motorbike' 'person' 'pottedplant'\n 'sheep' 'sofa' 'train' 'tvmonitor']\n(5683,)\n<TensorSliceDataset shapes: (20,), types: tf.float32>\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# Create dataset of image paths in test folder\n",
    "paths_ds = tf.data.Dataset.list_files(str(\"./VOC2007_test_subimages/*.jpg\"), shuffle=False)\n",
    "print(paths_ds)\n",
    "\n",
    "# Helpfer function to extract class/label names from paths\n",
    "def classnamefromPath(path):\n",
    "    parts = tf.strings.split(path, os.sep)\n",
    "    filename = parts[-1]\n",
    "    label = tf.strings.split(filename, '_')[-1]\n",
    "    label = tf.strings.split(label, '.')[0]\n",
    "\n",
    "    return label\n",
    "\n",
    "# Create list of label/class names\n",
    "labels = paths_ds.map(classnamefromPath)\n",
    "labels = np.array(list(labels.as_numpy_iterator()))\n",
    "labels = [label.decode('utf-8') for label in labels]\n",
    "label_names = np.unique(labels)\n",
    "print(label_names)\n",
    "\n",
    "# Helper fuction to convert string labels to class number\n",
    "def indexfromClassname(name, labels):\n",
    "    idx = np.where(labels == name)\n",
    "    return idx[0][0]\n",
    "\n",
    "# Create list of class indices\n",
    "labels_indices = [indexfromClassname(label, label_names) for label in labels]\n",
    "labels_indices = np.array(labels_indices)\n",
    "print(labels_indices.shape)\n",
    "\n",
    "# Encode class indices in one-hot form\n",
    "target_ds = tf.one_hot(labels_indices, len(label_names), on_value=1.0, off_value=0.0)\n",
    "target_ds = tf.data.Dataset.from_tensor_slices(target_ds)\n",
    "print(target_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to read images and pre-process images\n",
    "# InceptionV3 accepts input of size (299,299,3)\n",
    "# The input range is (-1,1)\n",
    "def readImages(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    image = tf.image.resize_with_pad(image, 299, 299)\n",
    "    image = keras.applications.inception_v3.preprocess_input(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Path: tf.Tensor(b'.\\\\VOC2007_test_subimages\\\\000001_dog.jpg', shape=(), dtype=string)\nLabel: dog\n(299, 299, 3)\n1.0\n-1.0\n"
    }
   ],
   "source": [
    "# print some information to check on images, label and target\n",
    "path = next(iter(paths_ds))\n",
    "image = readImages(path)\n",
    "\n",
    "print(\"Path: \" + str(path))\n",
    "print(\"Label: \" + str(next(iter(labels))))\n",
    "print(image.shape)\n",
    "print(np.max(image))\n",
    "print(np.min(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<MapDataset shapes: (299, 299, None), types: tf.float32>\n"
    }
   ],
   "source": [
    "# Create dataset of input data, pre-processed images\n",
    "images_ds = paths_ds.map(readImages)\n",
    "print(images_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<BatchDataset shapes: ((None, 299, 299, None), (None, 20)), types: (tf.float32, tf.float32)>\n"
    }
   ],
   "source": [
    "# Create main dataset from input and target datasets\n",
    "test_dataset = tf.data.Dataset.zip((images_ds, target_ds))\n",
    "test_dataset = test_dataset.batch(8)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "711/711 [==============================] - 336s 473ms/step - loss: 0.3872 - categorical_accuracy: 0.8870\n[0.3872477817604562, 0.8870315]\n"
    }
   ],
   "source": [
    "model = keras.models.load_model('inceptionv3_pascalvoc_0_1.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "eval = model.evaluate(test_dataset)\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}