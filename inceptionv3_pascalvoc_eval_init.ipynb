{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<TensorSliceDataset shapes: (), types: tf.string>\n['aeroplane' 'bicycle' 'bird' 'boat' 'bottle' 'bus' 'car' 'cat' 'chair'\n 'cow' 'diningtable' 'dog' 'horse' 'motorbike' 'person' 'pottedplant'\n 'sheep' 'sofa' 'train' 'tvmonitor']\n(5683,)\n<TensorSliceDataset shapes: (20,), types: tf.float32>\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# Create dataset of image paths in test folder\n",
    "paths_ds = tf.data.Dataset.list_files(str(\"./VOC2007_test_subimages/*.jpg\"), shuffle=False)\n",
    "print(paths_ds)\n",
    "\n",
    "# Helpfer function to extract class/label names from paths\n",
    "def classnamefromPath(path):\n",
    "    parts = tf.strings.split(path, os.sep)\n",
    "    filename = parts[-1]\n",
    "    label = tf.strings.split(filename, '_')[-1]\n",
    "    label = tf.strings.split(label, '.')[0]\n",
    "\n",
    "    return label\n",
    "\n",
    "# Create list of label/class names\n",
    "labels = paths_ds.map(classnamefromPath)\n",
    "labels = np.array(list(labels.as_numpy_iterator()))\n",
    "labels = [label.decode('utf-8') for label in labels]\n",
    "label_names = np.unique(labels)\n",
    "print(label_names)\n",
    "\n",
    "# Helper fuction to convert string labels to class number\n",
    "def indexfromClassname(name, labels):\n",
    "    idx = np.where(labels == name)\n",
    "    return idx[0][0]\n",
    "\n",
    "# Create list of class indices\n",
    "labels_indices = [indexfromClassname(label, label_names) for label in labels]\n",
    "labels_indices = np.array(labels_indices)\n",
    "print(labels_indices.shape)\n",
    "\n",
    "# Encode class indices in one-hot form\n",
    "target_ds = tf.one_hot(labels_indices, len(label_names), on_value=1.0, off_value=0.0)\n",
    "target_ds = tf.data.Dataset.from_tensor_slices(target_ds)\n",
    "print(target_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to read images and pre-process images\n",
    "# InceptionV3 accepts input of size (299,299,3)\n",
    "# The input range is (-1,1)\n",
    "def readImages(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    image = tf.image.resize_with_pad(image, 299, 299)\n",
    "    image = keras.applications.inception_v3.preprocess_input(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Path: tf.Tensor(b'.\\\\VOC2007_test_subimages\\\\000001_dog.jpg', shape=(), dtype=string)\nLabel: dog\n(299, 299, 3)\n1.0\n-1.0\n"
    }
   ],
   "source": [
    "# print some information to check on images, label and target\n",
    "path = next(iter(paths_ds))\n",
    "image = readImages(path)\n",
    "\n",
    "print(\"Path: \" + str(path))\n",
    "print(\"Label: \" + str(next(iter(labels))))\n",
    "print(image.shape)\n",
    "print(np.max(image))\n",
    "print(np.min(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<MapDataset shapes: (299, 299, None), types: tf.float32>\n"
    }
   ],
   "source": [
    "# Create dataset of input data, pre-processed images\n",
    "images_ds = paths_ds.map(readImages)\n",
    "print(images_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<BatchDataset shapes: ((None, 299, 299, None), (None, 20)), types: (tf.float32, tf.float32)>\n"
    }
   ],
   "source": [
    "# Create main dataset from input and target datasets\n",
    "test_dataset = tf.data.Dataset.zip((images_ds, target_ds))\n",
    "test_dataset = test_dataset.batch(8)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pre-trained model\n",
    "inceptionv3 = keras.applications.inception_v3.InceptionV3(weights='imagenet', input_shape=(299, 299, 3), include_top=False)\n",
    "\n",
    "# Add global spatial average pooling layer\n",
    "x = inceptionv3.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer to the raw output of network\n",
    "x = keras.layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a drop-out layer\n",
    "x = keras.layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "# Add a logistic layer (softmax) - to predict 10 classes\n",
    "predictions = keras.layers.Dense(20, activation='softmax')(x)\n",
    "\n",
    "# Compose the model based on new top-layer\n",
    "new_inceptionv3 = keras.models.Model(inputs=inceptionv3.input, outputs=predictions)\n",
    "\n",
    "# First: Train the new top-layer only\n",
    "# Hence, freeze all layers in pre-trained model\n",
    "for layer in inceptionv3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model, ready to be trained on new data\n",
    "new_inceptionv3.compile(optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9, decay=0.0001), loss=keras.losses.CategoricalCrossentropy(), metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "711/711 [==============================] - 328s 462ms/step - loss: 3.2638 - categorical_accuracy: 0.0320\n[3.2638261267907507, 0.032025337]\n"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval = new_inceptionv3.evaluate(test_dataset)\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}